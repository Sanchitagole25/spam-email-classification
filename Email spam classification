import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")
d:\python38\lib\site-packages\numpy\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:
d:\python38\lib\site-packages\numpy\.libs\libopenblas.4SP5SUA7CBGXUEOC35YP2ASOICYYEQZZ.gfortran-win_amd64.dll
d:\python38\lib\site-packages\numpy\.libs\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll
d:\python38\lib\site-packages\numpy\.libs\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll
d:\python38\lib\site-packages\numpy\.libs\libopenblas64__v0.3.21-gcc_10_3_0.dll
  warnings.warn("loaded more than 1 DLL from .libs:"
raw_mail_data = pd.read_csv("mail_data.csv")
raw_mail_data.head()
Category	Message
0	ham	Go until jurong point, crazy.. Available only ...
1	ham	Ok lar... Joking wif u oni...
2	spam	Free entry in 2 a wkly comp to win FA Cup fina...
3	ham	U dun say so early hor... U c already then say...
4	ham	Nah I don't think he goes to usf, he lives aro...
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score
raw_mail_data.isnull().sum()
Category    0
Message     0
dtype: int64
df = raw_mail_data.where((pd.notnull(raw_mail_data)), '')
df.isnull().sum()
Category    0
Message     0
dtype: int64
df.shape
(5572, 2)
# Supervised -> target class
# Unsupervised -> clustering problem

# Label encoding
df['Category'] = df['Category'].map({'spam': 0, 'ham': 1})
df.head()
Category	Message
0	1	Go until jurong point, crazy.. Available only ...
1	1	Ok lar... Joking wif u oni...
2	0	Free entry in 2 a wkly comp to win FA Cup fina...
3	1	U dun say so early hor... U c already then say...
4	1	Nah I don't think he goes to usf, he lives aro...
# loc function
df.loc[df['Category'] == 'spam', 'Category',] = 0
df.loc[df['Category'] == 'ham', 'Category',] = 1
df.head()
Category	Message
0	1	Go until jurong point, crazy.. Available only ...
1	1	Ok lar... Joking wif u oni...
2	0	Free entry in 2 a wkly comp to win FA Cup fina...
3	1	U dun say so early hor... U c already then say...
4	1	Nah I don't think he goes to usf, he lives aro...
X = df['Message']
Y = df['Category']
X
0       Go until jurong point, crazy.. Available only ...
1                           Ok lar... Joking wif u oni...
2       Free entry in 2 a wkly comp to win FA Cup fina...
3       U dun say so early hor... U c already then say...
4       Nah I don't think he goes to usf, he lives aro...
                              ...                        
5567    This is the 2nd time we have tried 2 contact u...
5568                 Will ü b going to esplanade fr home?
5569    Pity, * was in mood for that. So...any other s...
5570    The guy did some bitching but I acted like i'd...
5571                           Rofl. Its true to its name
Name: Message, Length: 5572, dtype: object
Y
0       1
1       1
2       0
3       1
4       1
       ..
5567    0
5568    1
5569    1
5570    1
5571    1
Name: Category, Length: 5572, dtype: int64
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)
X_train.shape
(4457,)
y_train.shape
(4457,)
X_test.shape
(1115,)
feature_extraction = TfidfVectorizer(min_df = 1, stop_words="english", binary=True)
X_train_features = feature_extraction.fit_transform(X_train)
X_test_features = feature_extraction.transform(X_test)
df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 5572 entries, 0 to 5571
Data columns (total 2 columns):
 #   Column    Non-Null Count  Dtype 
---  ------    --------------  ----- 
 0   Category  5572 non-null   int64 
 1   Message   5572 non-null   object
dtypes: int64(1), object(1)
memory usage: 87.2+ KB
y_train = y_train.astype("int")
y_test = y_test.astype("int")
X_train
1978    Reply to win £100 weekly! Where will the 2006 ...
3989    Hello. Sort of out in town already. That . So ...
3935     How come guoyang go n tell her? Then u told her?
4078    Hey sathya till now we dint meet not even a si...
4086    Orange brings you ringtones from all time Char...
                              ...                        
3772    Hi, wlcome back, did wonder if you got eaten b...
5191                               Sorry, I'll call later
5226        Prabha..i'm soryda..realy..frm heart i'm sory
5390                           Nt joking seriously i told
860               Did he just say somebody is named tampa
Name: Message, Length: 4457, dtype: object
print(X_train_features)
  (0, 5818)	0.22682143517864364
  (0, 2497)	0.2442158912653505
  (0, 694)	0.3171299579602537
  (0, 6264)	0.1898892037332199
  (0, 5800)	0.17558937755823417
  (0, 3262)	0.33791755486732394
  (0, 2049)	0.3034375179183143
  (0, 7300)	0.24288153842988894
  (0, 2724)	0.3544175987866074
  (0, 354)	0.3544175987866074
  (0, 7162)	0.2550284465664535
  (0, 258)	0.2379428657041507
  (0, 7222)	0.2173884735352799
  (0, 5512)	0.1898892037332199
  (1, 2555)	0.3840709491751004
  (1, 3804)	0.1902902346515268
  (1, 3932)	0.24325511357721427
  (1, 4509)	0.4028245991060671
  (1, 2440)	0.33870544648398715
  (1, 3333)	0.20665394084233096
  (1, 5650)	0.360444144470318
  (1, 2335)	0.2162321275166079
  (1, 6738)	0.28986069568918
  (1, 6109)	0.3239762634465801
  (1, 3267)	0.2678713077029217
  :	:
  (4452, 2438)	0.4574160733416501
  (4452, 7280)	0.3968991650168732
  (4452, 3978)	0.4574160733416501
  (4452, 3290)	0.26370969643076225
  (4452, 3084)	0.22948428918295163
  (4452, 2236)	0.2676662072392096
  (4453, 3874)	0.6064947019588056
  (4453, 4004)	0.5244851817485773
  (4453, 6108)	0.5975612693457145
  (4454, 6113)	0.4465347909835087
  (4454, 6114)	0.4465347909835087
  (4454, 5149)	0.43410473161397095
  (4454, 5409)	0.4079234999314281
  (4454, 3249)	0.3182708584577292
  (4454, 2893)	0.38087861810984514
  (4455, 5815)	0.5332274226200294
  (4455, 3691)	0.5541750775894743
  (4455, 4660)	0.4924788339394118
  (4455, 6686)	0.40745931976870786
  (4456, 4518)	0.5364209818026567
  (4456, 6078)	0.46545159250664164
  (4456, 6467)	0.48168628392630153
  (4456, 5719)	0.3276287995831882
  (4456, 2236)	0.31389751705425334
  (4456, 3720)	0.24023610815826446
print(X_test_features)
  (0, 4942)	0.27552235188443686
  (0, 4100)	0.3392428284838497
  (0, 3955)	0.3774291665065587
  (0, 3395)	0.402169324846608
  (0, 3225)	0.402169324846608
  (0, 2173)	0.30145841567028486
  (0, 2065)	0.36113324080559445
  (0, 1751)	0.34896165336060586
  (1, 7158)	0.3981347747267476
  (1, 6986)	0.2493471978387002
  (1, 6642)	0.326271353777915
  (1, 6544)	0.2204999931204713
  (1, 5430)	0.387052012561607
  (1, 4044)	0.3234324946551934
  (1, 3443)	0.3234324946551934
  (1, 1975)	0.3578586983359201
  (1, 1361)	0.37034060973735533
  (2, 6570)	0.3042743325149729
  (2, 5597)	0.43828336765880876
  (2, 4369)	0.4230992819157864
  (2, 3510)	0.4016985150384895
  (2, 3084)	0.21988546741069176
  (2, 3067)	0.21988546741069176
  (2, 2377)	0.4230992819157864
  (2, 1292)	0.3150204452887917
  :	:
  (1110, 6142)	0.22937745257301317
  (1110, 5204)	0.2537606265072484
  (1110, 4806)	0.26149679947415966
  (1110, 4497)	0.2874866271650959
  (1110, 4105)	0.23914254153997352
  (1110, 3938)	0.24167410415901527
  (1110, 3180)	0.3526556865484764
  (1110, 3084)	0.16868944269743877
  (1110, 2749)	0.2379337409312386
  (1110, 2437)	0.24437455884042017
  (1110, 2380)	0.3362376691126707
  (1110, 2173)	0.25203731054832607
  (1110, 2064)	0.2836273451638941
  (1111, 7095)	0.36365496598104324
  (1111, 3724)	0.42134339857243075
  (1111, 3258)	0.45132488164412626
  (1111, 2425)	0.4088782922446393
  (1111, 2410)	0.36365496598104324
  (1111, 1524)	0.4325555054026121
  (1112, 7390)	0.42586219706493256
  (1112, 6550)	0.691531900174862
  (1112, 4351)	0.5834595274323433
  (1113, 5796)	0.6364310164851212
  (1113, 1600)	0.48856109936052156
  (1113, 1472)	0.5968782232979806
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train_features, y_train)
LogisticRegression()
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.
prediction_train_data = model.predict(X_train_features)
accuracy_train_data = accuracy_score(y_train, prediction_train_data)
print("Accuarcy on train data: ", accuracy_train_data)
Accuarcy on train data:  0.9649988781691721
prediction_test_data = model.predict(X_test_features)
accuracy_test_data = accuracy_score(y_test, prediction_test_data)
print("Accuarcy on test data: ", accuracy_test_data)
Accuarcy on test data:  0.9659192825112107
# Building predictive system
input_user_mail = ["SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info"]

input_data_features = feature_extraction.transform(input_user_mail)

prediction = model.predict(input_data_features)

if prediction[0] == 1:
    print("This is a ham mail")
else:
    print("This is a spam mail")
This is a spam mail
import pickle
pickle.dump(model, open("logistic_regression.pkl", "wb"))
pickle.dump(feature_extraction, open("feature_extraction.pkl", "wb"))
 
